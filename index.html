<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html> <head>
<title>Karthik Paga's Home Page</title>
</head>

<body>
<h1>Venkata Rama KARTHIK PAGA</h1>

<p>I love to decipher and debug</p>
<b>
"I think that it's extraordinarily important that we in computer science keep fun in computing[...] What you know about computing other people will learn[...] The key to successful computing cannot be confined to your hands. What's in your hands, I think and hope, is intelligence: the ability to see the machine as more than when you were first led to it, that you can make it more." Alan J. Perlis (1922-1990)
</b>

<table width=100%>
<td>
<dl>
<dt><b>Research Work @</b>
 <dd> <p><a href="http://i4d.mit.edu/audio-tactile-speech-aids-for-the-deaf-hearing-impaired/">Centre for Innovation and Development, VIT university</a>  Creation Labs (project mangement @ http://www.openprojects.in/)</p>
 <dd> <a href="http://odin2.mech.ubc.ca/wiki/index.php/PR2_Wiki#Approved_Users">CARIS Lab~ Meche@UBC,</a> <a href="http://canwheel.org/aboutus/people/trainees/past">CanWheel Project,</a> <a href="https://www.cs.ubc.ca/cs-research/lci">Laboratory of Computational Intelligence~ CS@UBC</a> 
<dt><b> Contact: </b>
   <dd> email: paga (at) cs (dot) ubc (dot) ca,</a> 
   <dd> email: venkata (dot) makarthikpaga2011 (at) vit (dot) ac (dot) in</a>
   <dd> tel: (+91) 7598855445
   <dd> mail: H-356, John F Kennedy Block, VIT University, Vellore, TN-632014
   <dd> <a href = "http://pagakarthik.github.io/bio.html/">Story Teller</a> 
   <dd> <a href="https://twitter.com/KARTHIKPAGA">@KARTHIKPAGA</a>
<dt><b>Portfolio<b>
 <dd> <a href="https://github.com/pagakarthik">GitHub</a>
 <dd> <a href="https://www.linkedin.com/in/pagakarthik">LinkedIn</a>
 <dd> <a href="mailto:paga@cs.ubc.ca">Email</a>

</dl>
</td>
<td><img src="karthik.JPG" alt="Karthik Paga" style="width:250px;height:250px"></td>
</table>

<HR size = 2 width = "75%">

<table width=100%>
<td> 

<p>Interests and propective research topics:

<ul>

  <li>Feature based navigation of robots in constrained & unknown terrain

  <li>Obstacle shape estimation by using approximate comcentrations of simple geometric curves

  <li>Applications of SLAM in minimally invansive surgeries.

  <li>Validating novel algorithms such as iSAM2 and RISE etc., which could attend key issues(online, compuatational efficeicy, reduced data storage etc.)   in SLAM of mobile robots

  <li>Application of these algorithms to path planning for autonomous
  and semi-autonomous systems.

  <li>path planning and teleopration being the subsequent research topics in my interest for autonomy of robots. 

</ul>

<p>For those interested in experimenting the Point cloud library over ROS for robot perception on topics
 such as, euclidean cluster extarction, object pose estimation, sementation (minicut etc.) etc., I have published:

<h3><a href="https://github.com/pagakarthik/perception_pcl/tree/hydro-devel">The ROS tutorials for real time 3D point cloud processing</a></h3>

<p>I will soon update the wiki for consolidated a pipeline which can ease the simple tasks in robot perception (hobby projects) to identify the object and lablel each in the scene, segmentation, extract features or centroid estimation. These tutorials cover the modules which would form the robot perception tree. Individual explanations have been authored and well documented in their respective tutorials @ http://pointcloud.org. (comments included in respectice source scripts as well) --Happy Robot(ifying)--
</p>
</td>
<td><img src="pcl_logo.png" alt="Point cloud Library" style="width:125px;height:75px"></td>
<td><img src="ROS_logo.png" alt="Robot Operating System" style="width:125px;height:50px"></td>

</table>
<HR size = 2 width = "75%">


<h3>Capstone Project</h3>
<h4>Abstract</h4>
<p>Mobile robots (smart powered wheelchairs) for indoor navigation offer the possibility of
enhanced mobility to a large and growing population (most notably older adults), and a key
feature of such a chair is obstacle recognition and avoidance. Sensors are required to detect
nearby obstacles; however, complete sensor coverage of the immediate neighborhood is
challenging for reasons including financial, computational, aesthetic, user identity and sensor
reliability. However, direct modeling and control of commercial wheelchairs is not possible
because of proprietary internals and interfaces (standard CANBUS protocols). In this work we
design a dynamic egocentric occupancy map which maintains information about local obstacles
even when they are outside the field of view of the sensor system on the basis of a probabilistic
mapping scheme, thus serving as a task specific module. The end result of the SLAM algorithm
is an egocentric polar occupancy grid map published as a point cloud.
</p>
<p>Keywords: information agglomeration matrix, recursive state
estimation, obstacle detection, map estimation without full sensor coverage, bayes filter
algorithm, markov assumption. </p>
<p><a href="summary_of_work.pdf"> Copy of the design report</a>
</p>
This project extends 
"A risk assessment infrastructure for powered wheelchair motion commands without full sensor coverage" work done by Pouria Talebifard et al.,  presented at <a href="https://ras.papercept.net/conferences/conferences/IROS14/program/IROS14_ContentListWeb_4.html"> IROS 2014, Chicago</a>
<HR size = 2 width = "75%">
<h4>Validation</h4>
<table width=100%>
<td>
The first image (left) describes an indoor navigation scene, a static obstacle (blue recycling bin) in the mid way of the robot. The 2nd image (right) depicts (the map) the same scene as perceived by the robot. We can infer that the map generated is a close representation of the ground truth and the algorithm performs well at classifying the navigable space, obstacles and the occluded region. 
<p>The spectral color of each node in the map represents a quantitative value (Belief) which indicates the region around the node to be navigable. Higher the value, greater the likelihood for the region to be obstacle free. 
<p>VIBGYOR: violet-> not navigable...yellow-> equally likely...red-> navigable 
<td><img src="scene.png" alt="original scene" style="width:550px;height:500px"></td>
<td><img src="d1.png" alt="Dynamic Egocentric map" style="width:550px;height:500px"></td>

</table>

<HR size = 2 width = "75%">
<h3> ROBOTS :) </h3>
<table width=100%>
<td> 

Personal and Assistive Robot: Smart powered Wheelchair: Collaborative control (or) shared control policy
<a href= "http://www.canwheel.ca/our-research/current-projects/project-iii/">CanWheel</a> 

</td>
<td><img src="paga.jpg" alt="original scene" style="width:350px;height:300px"></td>
<td> 

PR2 : Personal robot: Research robot 
<a href= "http://caris.mech.ubc.ca/research/experiments/#matthew">Charlie</a> 

</td>
<td><img src="charlie.jpg" alt="PR2" style="width:350px;height:300px"></td>
</table>

<HR size = 2 width = "75%">

<p>
<h2>Suggested Readings: Robotics and Computational intelligence</h2>
<b>
<p>* <a href="http://robots.stanford.edu/papers/thrun.iros01-occmap.pdf">Occupancy Grids, a wonderful reading for beginners (S.Thrun @CMU)</a></p>
<p>* Probablistic Robotics by Wolfram Burgard, Dieter Fox, and Sebastian Thrun</p>
<p>* Springer Handbook of Robotics, editors: Bruno Siciliano, Oussama Khatib </p>
<p>* Handbook of Machine Vision, edited by Alexander Hornberg </p>
<p>* The Bayes Tree: An Algorithmic Foundation for
Probabilistic Robot Mapping, authors: Michael Kaess, Viorela Ila, Richard Roberts and Frank Dellaert</p>
<h4>Discussions</h4>
	<a href="http://www.cs.ubc.ca/nest/lci/robuds/">Robuddies Reading Group [June-August]</a>
</b>
</p>
<p>
<h3>Tutorials</h3>
<b>
* <a href="http://wiki.ros.org/pcl/Tutorials">updated PCl Wiki for ROS_hydro (work done with the Neil Traft and team as part of the PR2-hackathon)</a>
* <a href="https://github.com/pagakarthik/perception_pcl/tree/hydro-devel/pcl_ros_hydro">PCl tutorials for ROS_hydro</a>
</b>
</p>
<HR size = 2 width = "75%">
<p>
<h3>Interesting projects driven towards positive social impact :)</h4>
<b>
<p>Low cost digital microscope wiht fully automated stage, serves the basic purpose of digital microscope. 
 <a href="http://www.instructables.com/id/Low-cost-digital-microscope-with-automated-slide-m/">Instructables</a></p>
<p>Affordable Audio Tactile Speech aids for the deaf and hearing impaired
 <a href="http://i4d.mit.edu/audio-tactile-speech-aids-for-the-deaf-hearing-impaired/">Innovation Centre (http://i4d.mit.edu)</a></p></p>
</b>
</p>
<HR size = 2 width = "75%">
<h2>Organization and Labs</h2>
<p> *<a href="http://www.openprojects.in/">Creation Labs, Global presence via Open Projects</a></p>
<p> *<a href="http://i4d.mit.edu/">Innovation for Development(http://i4d.mit.edu)</a></p>
<p> *<a href="https://www.cs.ubc.ca/cs-research/lci">Laboratory of Computational Intelligence @UBC,Vancuover</a></p>
<p> *Materials Engineering Laboratory, VIT University Vellore</p>
<p> *<a href="http://makerfest.com/">Maker/ presenter @makerfest_MJFF_2014</a></p>
<p> *<a href="https://www.mitacs.ca/en/programs/globalink/globalink-research-internship">Globalink ambassdor @MITACS</a></p>
<p> *<a href="http://www.thelattice.in/">R&D intern with GLOCAL, medtech team</a></p>
<p> *<a href="http://www.jugaadathon.com/">Jugaadathon~ Proud participant and alumni</a></p>
<p> *<a href="http://www.massgeneralcenterforglobalhealth.org/camtech/">CAMtech</a></p>

<HR size = 2 width = "75%">

<address>

<p>
Created 26 October 2014.<br>
Last updated 16 December 2014.<br>

Created and maintained by <a
HREF="http://pagakarthik.github.io/">Karthik Paga</a>.

</address>
</body>
</html>
